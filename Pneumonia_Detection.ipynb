{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSGn6yypo8iVeHLVWWx7f6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Upload kaggle.json\")\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "L6ABjn7kLVP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloads to /content\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A5FtY8SACYD",
        "outputId": "4704c890-d4ff-448a-e5a3-43d87a8dfc82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            " 98% 2.25G/2.29G [00:19<00:00, 144MB/s]\n",
            "100% 2.29G/2.29G [00:20<00:00, 122MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/chest-xray-pneumonia.zip -d /content/chest_xray\n",
        "!ls -la /content/chest_xray\n",
        "!find /content/chest_xray -maxdepth 2 -type d -print\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lTC5ToqAE1A",
        "outputId": "f9b5af3c-35b5-426c-8d60-7a4a2d2471a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Dec  2 17:02 .\n",
            "drwxr-xr-x 1 root root 4096 Dec  2 17:02 ..\n",
            "drwxr-xr-x 7 root root 4096 Dec  2 17:03 chest_xray\n",
            "/content/chest_xray\n",
            "/content/chest_xray/chest_xray\n",
            "/content/chest_xray/chest_xray/__MACOSX\n",
            "/content/chest_xray/chest_xray/val\n",
            "/content/chest_xray/chest_xray/test\n",
            "/content/chest_xray/chest_xray/chest_xray\n",
            "/content/chest_xray/chest_xray/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Imports + hyperparameters + helpful checks"
      ],
      "metadata": {
        "id": "CNHVg3QhBPP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Hyperparams\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "INITIAL_LR = 1e-3\n",
        "FINE_TUNE_LR = 1e-5\n",
        "\n",
        "# Dataset paths\n",
        "TRAIN_DIR = \"/content/chest_xray/chest_xray/train\"\n",
        "VAL_DIR   = \"/content/chest_xray/chest_xray/val\"\n",
        "TEST_DIR  = \"/content/chest_xray/chest_xray/test\"\n",
        "\n",
        "# quick file counts\n",
        "def count_files(d):\n",
        "    total = 0\n",
        "    for root, _, files in os.walk(d):\n",
        "        total += len([f for f in files if f.lower().endswith(('.png','.jpg','.jpeg'))])\n",
        "    return total\n",
        "\n",
        "print(\"train images (original):\", count_files(TRAIN_DIR))\n",
        "print(\"val folder images (original):\", count_files(VAL_DIR))\n",
        "print(\"test images:\", count_files(TEST_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bux58mVBBAH6",
        "outputId": "1739d0fe-4984-43cc-ad8b-3ab9c2452f28"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train images (original): 5216\n",
            "val folder images (original): 16\n",
            "test images: 624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build data generators (use validation_split from TRAIN_DIR so validation isn't tiny)"
      ],
      "metadata": {
        "id": "_UUXKOTGBdsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train generator with validation_split\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.08,\n",
        "    height_shift_range=0.08,\n",
        "    shear_range=0.08,\n",
        "    zoom_range=0.08,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.10   # 10% of TRAIN_DIR for validation\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "steps_per_epoch = math.ceil(train_gen.samples / BATCH_SIZE)\n",
        "validation_steps = math.ceil(val_gen.samples / BATCH_SIZE)\n",
        "test_steps = math.ceil(test_gen.samples / BATCH_SIZE)\n",
        "\n",
        "print(\"train samples:\", train_gen.samples, \"val samples:\", val_gen.samples, \"test samples:\", test_gen.samples)\n",
        "print(\"steps_per_epoch:\", steps_per_epoch, \"validation_steps:\", validation_steps, \"test_steps:\", test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoQ3kxaJBZCa",
        "outputId": "148a95b4-0e59-47c9-aa6c-4c55d54a2895"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4695 images belonging to 2 classes.\n",
            "Found 521 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "train samples: 4695 val samples: 521 test samples: 624\n",
            "steps_per_epoch: 294 validation_steps: 33 test_steps: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### compute class weights"
      ],
      "metadata": {
        "id": "b8OQr4D_CUK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "classes = np.unique(train_gen.classes)\n",
        "class_weights = compute_class_weight('balanced', classes=classes, y=train_gen.classes)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(\"class_weights:\", class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzutIE-qBvyN",
        "outputId": "16951ee1-5f8e-49ca-ff1e-7a6a48908687"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_weights: {0: np.float64(1.9449047224523612), 1: np.float64(0.6730217889908257)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### MODEL MobileNetV2"
      ],
      "metadata": {
        "id": "q-Id8eSUCcq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = MobileNetV2(input_shape=IMAGE_SIZE + (3,), include_top=False, weights='imagenet')\n",
        "base.trainable = False\n",
        "\n",
        "inp = Input(shape=IMAGE_SIZE + (3,))\n",
        "x = base(inp, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inp, out)\n",
        "model.compile(optimizer=Adam(INITIAL_LR), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "bA_YuVjrCXD-",
        "outputId": "01846ff5-d8eb-4937-a129-10ccbc268106"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,081\u001b[0m (9.24 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,081</span> (9.24 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,097\u001b[0m (641.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,097</span> (641.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Callbacks"
      ],
      "metadata": {
        "id": "pdg5UrRHClGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es  = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1)\n",
        "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1)\n",
        "ckp = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)"
      ],
      "metadata": {
        "id": "lMq1xCRWChKS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Stage 1: Train top (frozen base)"
      ],
      "metadata": {
        "id": "Y0bPnmi1CtY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS_STAGE1 = 8\n",
        "\n",
        "history1 = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=EPOCHS_STAGE1,\n",
        "    callbacks=[es, rlp, ckp],\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uADlvjoCo6v",
        "outputId": "02fc6ead-af8a-4c10-893d-c0739d809af0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.8679 - auc: 0.9403 - loss: 0.2913\n",
            "Epoch 1: val_loss improved from inf to 0.19496, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 425ms/step - accuracy: 0.8680 - auc: 0.9404 - loss: 0.2910 - val_accuracy: 0.9117 - val_auc: 0.9848 - val_loss: 0.1950 - learning_rate: 0.0010\n",
            "Epoch 2/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9400 - auc: 0.9867 - loss: 0.1463\n",
            "Epoch 2: val_loss improved from 0.19496 to 0.16199, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 329ms/step - accuracy: 0.9400 - auc: 0.9867 - loss: 0.1463 - val_accuracy: 0.9386 - val_auc: 0.9884 - val_loss: 0.1620 - learning_rate: 0.0010\n",
            "Epoch 3/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9504 - auc: 0.9888 - loss: 0.1277\n",
            "Epoch 3: val_loss did not improve from 0.16199\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 328ms/step - accuracy: 0.9504 - auc: 0.9888 - loss: 0.1277 - val_accuracy: 0.9309 - val_auc: 0.9902 - val_loss: 0.1816 - learning_rate: 0.0010\n",
            "Epoch 4/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9461 - auc: 0.9907 - loss: 0.1198\n",
            "Epoch 4: val_loss improved from 0.16199 to 0.12353, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 327ms/step - accuracy: 0.9461 - auc: 0.9907 - loss: 0.1198 - val_accuracy: 0.9443 - val_auc: 0.9901 - val_loss: 0.1235 - learning_rate: 0.0010\n",
            "Epoch 5/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9473 - auc: 0.9900 - loss: 0.1238\n",
            "Epoch 5: val_loss did not improve from 0.12353\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 325ms/step - accuracy: 0.9473 - auc: 0.9900 - loss: 0.1237 - val_accuracy: 0.9539 - val_auc: 0.9926 - val_loss: 0.1238 - learning_rate: 0.0010\n",
            "Epoch 6/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9597 - auc: 0.9917 - loss: 0.1076\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.12353\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 329ms/step - accuracy: 0.9597 - auc: 0.9917 - loss: 0.1076 - val_accuracy: 0.9328 - val_auc: 0.9915 - val_loss: 0.1535 - learning_rate: 0.0010\n",
            "Epoch 7/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9592 - auc: 0.9929 - loss: 0.1014\n",
            "Epoch 7: val_loss did not improve from 0.12353\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 329ms/step - accuracy: 0.9592 - auc: 0.9929 - loss: 0.1014 - val_accuracy: 0.9405 - val_auc: 0.9878 - val_loss: 0.1680 - learning_rate: 2.0000e-04\n",
            "Epoch 8/8\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9686 - auc: 0.9948 - loss: 0.0816\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.12353\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 326ms/step - accuracy: 0.9686 - auc: 0.9948 - loss: 0.0816 - val_accuracy: 0.9347 - val_auc: 0.9916 - val_loss: 0.1657 - learning_rate: 2.0000e-04\n",
            "Epoch 8: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Stage 2: Fine-tune (unfreeze some layers)"
      ],
      "metadata": {
        "id": "uTSBrFrsGj9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze last 20 layers\n",
        "for layer in base.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "for layer in base.layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=Adam(FINE_TUNE_LR), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "EPOCHS_STAGE2 = 6\n",
        "history2 = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=EPOCHS_STAGE2,\n",
        "    callbacks=[es, rlp, ckp],\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xVF5axwCxEI",
        "outputId": "7e79d360-852d-4f19-a862-984b3fe0d4c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9173 - auc: 0.9676 - loss: 0.2466\n",
            "Epoch 1: val_loss did not improve from 0.12353\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 385ms/step - accuracy: 0.9173 - auc: 0.9677 - loss: 0.2465 - val_accuracy: 0.9482 - val_auc: 0.9774 - val_loss: 0.1462 - learning_rate: 1.0000e-05\n",
            "Epoch 2/6\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9377 - auc: 0.9821 - loss: 0.1638\n",
            "Epoch 2: val_loss did not improve from 0.12353\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 335ms/step - accuracy: 0.9377 - auc: 0.9821 - loss: 0.1638 - val_accuracy: 0.9386 - val_auc: 0.9871 - val_loss: 0.1449 - learning_rate: 1.0000e-05\n",
            "Epoch 3/6\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9383 - auc: 0.9856 - loss: 0.1553\n",
            "Epoch 3: val_loss improved from 0.12353 to 0.09022, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 328ms/step - accuracy: 0.9383 - auc: 0.9856 - loss: 0.1553 - val_accuracy: 0.9597 - val_auc: 0.9941 - val_loss: 0.0902 - learning_rate: 1.0000e-05\n",
            "Epoch 4/6\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9467 - auc: 0.9879 - loss: 0.1314\n",
            "Epoch 4: val_loss did not improve from 0.09022\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 326ms/step - accuracy: 0.9467 - auc: 0.9879 - loss: 0.1314 - val_accuracy: 0.9559 - val_auc: 0.9854 - val_loss: 0.1453 - learning_rate: 1.0000e-05\n",
            "Epoch 5/6\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9441 - auc: 0.9851 - loss: 0.1480\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.09022\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 328ms/step - accuracy: 0.9442 - auc: 0.9852 - loss: 0.1480 - val_accuracy: 0.9578 - val_auc: 0.9943 - val_loss: 0.0916 - learning_rate: 1.0000e-05\n",
            "Epoch 6/6\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.9557 - auc: 0.9930 - loss: 0.1030\n",
            "Epoch 6: val_loss did not improve from 0.09022\n",
            "\u001b[1m294/294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 326ms/step - accuracy: 0.9557 - auc: 0.9930 - loss: 0.1030 - val_accuracy: 0.9501 - val_auc: 0.9914 - val_loss: 0.1116 - learning_rate: 2.0000e-06\n",
            "Restoring model weights from the end of the best epoch: 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"best_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMb96D4GGs07",
        "outputId": "e8c8b732-02a8-49f0-ca14-a86b44ee6e49"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_auc = model.evaluate(test_gen)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"Test AUC:\", test_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jTf_jnsJ3Bm",
        "outputId": "6cdfd52f-23d9-479d-9e19-40a695ac1a26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - accuracy: 0.7606 - auc: 0.6059 - loss: 0.8401\n",
            "Test Accuracy: 0.8557692170143127\n",
            "Test AUC: 0.9351304769515991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMbk_Py-J7cC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}